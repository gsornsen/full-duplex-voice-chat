# Procfile.agent - Development services with LiveKit Agent orchestrator
# Usage: honcho start -f Procfile.agent
# Or via Just: just dev-agent
#
# This is the same as Procfile.dev but replaces the old orchestrator with the new LiveKit Agent

# LiveKit Server - WebRTC media server
# Uses Docker container with dev config
livekit: docker run --rm --name livekit-dev-honcho --stop-timeout 10 -p 7880:7880 -p 7881:7881 -p 7882:7882/udp -v $PWD/configs/livekit.yaml:/etc/livekit.yaml:ro livekit/livekit-server:latest --config /etc/livekit.yaml

# Caddy - HTTPS/WSS reverse proxy
# Provides SSL termination for frontend (8443) and LiveKit WebSocket (8444)
# Requires: Caddyfile, voicechat.local+3.pem, voicechat.local+3-key.pem
caddy: docker run --rm --name caddy-dev-honcho --stop-timeout 10 -p 8443:8443 -p 8444:8444 -p 80:80 -v $PWD/Caddyfile:/etc/caddy/Caddyfile:ro -v $PWD/voicechat.local+3.pem:/etc/caddy/voicechat.local+3.pem:ro -v $PWD/voicechat.local+3-key.pem:/etc/caddy/voicechat.local+3-key.pem:ro --add-host host.docker.internal:host-gateway caddy:2-alpine

# TTS Worker - Text-to-speech gRPC server (Phase 3 COMPLETE - integrated with agent!)
# Using Piper adapter (CPU-based TTS, realistic speech output)
# Note: First run downloads ~60MB model (~30s)
# Connected to agent via custom grpc_tts plugin
tts: uv run python -u -m src.tts --adapter piper --default-model piper-en-us-lessac-medium --port 7001

# LiveKit Agent - Orchestrator using livekit-agents SDK
# Phases 1-3 COMPLETE: Now using custom WhisperX STT + gRPC TTS (Piper) + OpenAI LLM
# Custom plugins:
#   - whisperx.STT: 4-8x faster than standard Whisper
#   - grpc_tts.TTS: Connects to TTS worker above (Piper adapter)
#   - openai.LLM: Still using OpenAI (Phase 4 will make this optional)
# Requires: LIVEKIT_URL, LIVEKIT_API_KEY, LIVEKIT_API_SECRET, OPENAI_API_KEY in .env
agent: uv run python -u -m src.orchestrator.agent dev

# Web Client - Next.js development server
# Uncomment to run frontend alongside backend
web: cd src/client/web && npm run dev

