[pytest]
minversion = 8.0
addopts = -v --strict-markers --tb=short --strict-config
testpaths = tests
asyncio_mode = auto
asyncio_default_fixture_loop_scope = module
asyncio_default_test_loop_scope = module

# Test markers for categorization
markers =
    unit: Unit tests (fast, no external dependencies)
    integration: Integration tests (require Docker services via fixtures or GitHub Actions service containers)
    docker: Tests requiring Docker (may skip if unavailable)
    redis: Tests requiring Redis container
    livekit: Tests requiring LiveKit container
    performance: Performance benchmark tests
    slow: Tests that take longer to run (> 5s)
    grpc: Tests that use gRPC (require --forked for process isolation)
    grpc_unsafe: Tests that may segfault in certain environments (WSL2, etc.)
    requires_grpc: Tests that require a gRPC-safe environment to run
    gpu: Tests requiring GPU (CUDA)
    infrastructure: Infrastructure smoke tests (Docker Compose, just commands) - excluded from CI due to flakiness on shared runners
    ci_skip: Tests that should be skipped in CI environments (run locally only)

# Logging
log_cli = false
log_cli_level = INFO
log_file = tests/logs/pytest.log
log_file_level = DEBUG

# Warnings
filterwarnings =
    error
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore:pkg_resources is deprecated:UserWarning

# Process Isolation for Test Stability
# -------------------------------------
# The --forked flag runs each test in a separate subprocess for better isolation.
# This is particularly important for:
#
# 1. gRPC tests: Prevents segfaults from grpc-python background threads
#    accessing garbage-collected event loops
#
# 2. Model downloads: Isolates WhisperX/CosyVoice model downloads that may
#    consume significant disk space (multi-GB files)
#
# 3. GPU memory: Ensures CUDA memory is properly released between tests
#
# 4. State isolation: Prevents shared state pollution between tests
#
# Usage in CI:
#   pytest tests/ --forked -v -m "not infrastructure and not gpu"
#
# Local testing:
#   pytest tests/integration/ --forked -v  # Integration tests only
#   pytest tests/ --forked                 # All tests with isolation
#
# Trade-offs:
#   - Slower execution (process spawn overhead)
#   + Better isolation (prevents cascading failures)
#   + Disk space management (subprocess cleanup after each test)
#   + Prevents memory leaks from accumulating
#
# See also:
# - GRPC_SEGFAULT_WORKAROUND.md for gRPC-specific issues
# - .github/workflows/pr-ci.yml for CI configuration

# Infrastructure Tests
# ---------------------
# Tests marked with @pytest.mark.infrastructure validate development workflow
# tooling (Docker Compose, justfile commands) and are EXCLUDED from CI due to
# inherent flakiness on shared GitHub Actions runners.
#
# These tests are valuable for local development validation but unsuitable for
# CI environments due to:
# - Resource contention on shared runners (2 CPU, 7GB RAM)
# - Unpredictable Docker daemon performance
# - Network timing variability (image pulls, health checks)
#
# To run infrastructure tests locally:
#   pytest tests/integration/test_unified_workflow.py -v -m infrastructure
#
# To run all tests EXCEPT infrastructure tests (CI default):
#   pytest tests/ -v -m "not infrastructure"

# Integration Tests
# -----------------
# Integration tests now run in CI with GitHub Actions service containers:
# - Redis service container provides redis://localhost:6379
# - Tests start mock TTS workers and orchestrator as Python processes (not containers)
# - Tests use dynamic port allocation to avoid conflicts
# - Each test fixture creates unique container names for isolation
#
# CI configuration:
#   pytest tests/ --forked -v -m "not infrastructure and not gpu"
#
# This runs ALL tests including integration tests, excluding only:
# - infrastructure: Flaky workflow tests (Docker Compose, etc.)
# - gpu: GPU-accelerated tests (run on separate GPU runners)
