name: PR CI

# Comprehensive CI for pull requests to main
# - Runs full test suite (all 730 tests)
# - Collects code coverage with Codecov
# - Enforces quality gates (lint, typecheck, tests must pass)
# - Status is REQUIRED (blocks merge if failing)
# - Uses aggressive caching for faster runs
# - GPU tests run in parallel on dedicated runners
# - Integration tests run with Docker service containers

on:
  pull_request:
    branches:
      - main
    types: [opened, synchronize, reopened]

env:
  PYTHON_VERSION: "3.13"
  UV_VERSION: "latest"

jobs:
  lint:
    name: Lint (ruff)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run ruff
        run: uv run ruff check src/ tests/

  typecheck:
    name: Type Check (mypy)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # Use composite action for DRY setup
      - name: Setup test environment
        uses: ./.github/actions/setup-test-env
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          uv-version: ${{ env.UV_VERSION }}

      - name: Run mypy
        run: uv run mypy src/ tests/

  test:
    name: Test (pytest - CPU suite)
    runs-on: ubuntu-latest
    permissions:
      # Public new comments on PRs and update existing comments created
      # by this job
      pull-requests: write
      contents: write

    # Service containers for integration tests
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      # Free up disk space before installation
      - name: Free disk space
        run: |
          echo "Before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
          echo "After cleanup:"
          df -h

      # Use composite action for DRY setup
      - name: Setup test environment
        uses: ./.github/actions/setup-test-env
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          uv-version: ${{ env.UV_VERSION }}

      # Clean uv cache after install to save space
      - name: Clean uv cache
        run: |
          uv cache clean
          echo "After cache clean:"
          df -h

      # Verify Redis is available

      - name: Run pytest with coverage (including integration tests)
        run: |
          # Run all tests EXCEPT GPU and infrastructure tests
          # Integration tests now included with Redis service container
          uv run pytest tests/ \
            -v \
            -m "not infrastructure and not gpu" \
            --forked \
            --cov=src \
            --cov-report=xml:coverage-cpu.xml \
            --cov-report=term \
            --cov-report=html:htmlcov-cpu \
            --tb=short \
            --junitxml=test-results-cpu.xml \
            -o junit_family=legacy
        env:
          # Redis is available via service container on localhost:6379
          REDIS_URL: "redis://localhost:6379"

      # Clean up test artifacts to free space
      - name: Clean test cache
        if: always()
        run: |
          rm -rf .pytest_cache
          rm -rf htmlcov-cpu
          echo "After test cleanup:"
          df -h

      - name: Upload CPU coverage to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage-cpu.xml
          flags: pytest-cpu
          name: codecov-pr-ci-cpu
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload CPU test results to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/test-results-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./test-results-cpu.xml
          flags: pytest-cpu
          name: codecov-test-results-cpu
          fail_ci_if_error: false
          verbose: true

      - name: Upload CPU test results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-pr-ci-cpu
          path: |
            coverage-cpu.xml
            test-results-cpu.xml
          retention-days: 30

  # GPU tests job (runs in parallel with CPU tests)
  gpu-tests:
    name: GPU Tests (PyTorch CUDA)
    # Use CIRun GPU runner with unique label per run for isolation
    runs-on: "cirun-gpu-8g--${{ github.run_id }}"
    permissions:
      pull-requests: write
      contents: write

    # Service containers for integration tests on GPU runner
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      # Verify GPU availability (sanity check)
      - name: Verify GPU hardware
        run: |
          echo "=== GPU Hardware Check ==="
          nvidia-smi
          echo ""
          echo "GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader)"
          echo "Driver: $(nvidia-smi --query-gpu=driver_version --format=csv,noheader)"
          echo "CUDA: $(nvidia-smi --query-gpu=cuda_version --format=csv,noheader)"
          echo ""
          echo "=== GPU Memory ==="
          nvidia-smi --query-gpu=memory.total,memory.free --format=csv,noheader

      # Use composite action for DRY setup (skip OS deps - pre-installed on GPU runner)
      - name: Setup test environment
        uses: ./.github/actions/setup-test-env
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          uv-version: ${{ env.UV_VERSION }}
          skip-os-deps: "true"

      # Verify PyTorch CUDA availability
      - name: Verify PyTorch CUDA
        run: |
          uv run python -c "
          import torch
          import sys

          print('=== PyTorch Configuration ===')
          print(f'PyTorch version: {torch.__version__}')
          print(f'CUDA available: {torch.cuda.is_available()}')

          if torch.cuda.is_available():
              print(f'CUDA version: {torch.version.cuda}')
              print(f'cuDNN version: {torch.backends.cudnn.version()}')
              print(f'GPU count: {torch.cuda.device_count()}')
              print(f'GPU name: {torch.cuda.get_device_name(0)}')
              print(f'GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')
          else:
              print('ERROR: CUDA not available in PyTorch!')
              sys.exit(1)
          "


      # Run GPU-specific tests with coverage
      - name: Run GPU tests with coverage
        run: |
          echo "Running GPU-accelerated tests (marked with @pytest.mark.gpu)"
          uv run pytest tests/ \
            -v \
            -m "gpu" \
            --forked \
            --cov=src \
            --cov-report=xml:coverage-gpu.xml \
            --cov-report=term \
            --cov-report=html:htmlcov-gpu \
            --tb=short \
            --junitxml=test-results-gpu.xml \
            -o junit_family=legacy
        env:
          # Ensure GPU tests run even if CUDA_VISIBLE_DEVICES is set
          CUDA_VISIBLE_DEVICES: "0"
          # Redis is available via service container
          REDIS_URL: "redis://localhost:6379"

      - name: Upload GPU coverage to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage-gpu.xml
          flags: pytest-gpu
          name: codecov-pr-ci-gpu
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload GPU test results to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/test-results-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./test-results-gpu.xml
          flags: pytest-gpu
          name: codecov-test-results-gpu
          fail_ci_if_error: false
          verbose: true

      - name: Upload GPU test results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-pr-ci-gpu
          path: |
            coverage-gpu.xml
            test-results-gpu.xml
          retention-days: 30

  build:
    name: Build Check
    runs-on: ubuntu-latest
    needs: [lint, typecheck, test, gpu-tests]
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Verify uv lock
        run: |
          uv lock --check
          uv sync --frozen

      - name: Build success
        run: |
          echo "## ✅ PR CI Build Successful!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All quality gates passed:" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Linting (ruff)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Type checking (mypy)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ CPU test suite (pytest + integration)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ GPU test suite (pytest)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Code coverage (codecov)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Build verification (uv lock)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**This PR is ready to merge!** 🎉" >> $GITHUB_STEP_SUMMARY

  # Security scanning with Bandit
  security:
    name: Security Scan (bandit)
    runs-on: ubuntu-latest
    continue-on-error: true  # Don't block PR if security scan fails
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install bandit
        run: uv tool install bandit[toml]

      - name: Run bandit
        run: |
          uv tool run bandit -r src/ -f json -o bandit-report.json || true
          uv tool run bandit -r src/ -f txt || true

      - name: Upload security report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-report
          path: bandit-report.json
          retention-days: 30

  # Dependency vulnerability scanning
  dependency-check:
    name: Dependency Check
    runs-on: ubuntu-latest
    continue-on-error: true  # Don't block PR if dependency check fails
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Install pip-audit in project environment
        run: uv pip install pip-audit

      - name: Run pip-audit on project dependencies
        run: |
          uv run pip-audit --desc --output pip-audit-report.json --format json || true
          uv run pip-audit --desc || true

      - name: Upload dependency report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dependency-report
          path: pip-audit-report.json
          retention-days: 30
