name: PR CI

# Comprehensive CI for pull requests to main
# - Runs full test suite in batches to avoid OOM (GitHub Actions runners have 7GB RAM)
# - Batch 1: Unit tests (~907 tests, ~2GB RAM, fast)
# - Batch 2: Integration tests (~208 tests, ~3GB RAM, needs Redis)
# - Batch 3: GPU tests (~20 tests, ~4GB RAM, dedicated runner)
# - Collects code coverage with Codecov
# - Enforces quality gates (lint, typecheck, tests must pass)
# - Status is REQUIRED (blocks merge if failing)
# - Uses aggressive caching for faster runs

on:
  pull_request:
    branches:
      - main
    types: [opened, synchronize, reopened]

env:
  PYTHON_VERSION: "3.13"
  UV_VERSION: "latest"

jobs:
  lint:
    name: Lint (ruff)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run ruff
        run: uv run ruff check src/ tests/

  typecheck:
    name: Type Check (mypy)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # Use composite action for DRY setup
      - name: Setup test environment
        uses: ./.github/actions/setup-test-env
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          uv-version: ${{ env.UV_VERSION }}

      - name: Run mypy
        run: uv run mypy src/ tests/

  # Batch 1: Unit tests only (fast, no external dependencies, ~2GB RAM)
  test-unit:
    name: Test (Unit - Batch 1/3)
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: write

    steps:
      - uses: actions/checkout@v4

      # Free up disk space before installation
      - name: Free disk space
        run: |
          echo "Before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
          echo "After cleanup:"
          df -h

      # Use composite action for DRY setup
      - name: Setup test environment
        uses: ./.github/actions/setup-test-env
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          uv-version: ${{ env.UV_VERSION }}

      # Clean uv cache after install to save space
      - name: Clean uv cache
        run: |
          uv cache clean
          echo "After cache clean:"
          df -h

      # Run unit tests only (fast, no Docker/Redis needed)
      - name: Run unit tests with coverage
        timeout-minutes: 20
        run: |
          echo "=== Batch 1: Unit Tests (~907 tests) ==="
          uv run pytest tests/unit/ \
            -v \
            -m "not infrastructure and not gpu" \
            --cov=src \
            --cov-report=xml:coverage-unit.xml \
            --cov-report=term \
            --cov-report=html:htmlcov-unit \
            --tb=short \
            --junitxml=test-results-unit.xml \
            -o junit_family=legacy

      # Clean up test artifacts to free space
      - name: Clean test cache
        if: always()
        run: |
          rm -rf .pytest_cache
          rm -rf htmlcov-unit
          echo "After test cleanup:"
          df -h

      - name: Upload unit coverage to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage-unit.xml
          flags: pytest-unit
          name: codecov-pr-ci-unit
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload unit test results to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/test-results-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./test-results-unit.xml
          flags: pytest-unit
          name: codecov-test-results-unit
          fail_ci_if_error: false
          verbose: true

      - name: Upload unit test results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-pr-ci-unit
          path: |
            coverage-unit.xml
            test-results-unit.xml
          retention-days: 30

  # Batch 2: Integration tests (needs Redis, ~3GB RAM)
  test-integration:
    name: Test (Integration - Batch 2/3)
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: write

    # Service containers for integration tests
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      # Free up disk space before installation
      - name: Free disk space
        run: |
          echo "Before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
          echo "After cleanup:"
          df -h

      # Use composite action for DRY setup
      - name: Setup test environment
        uses: ./.github/actions/setup-test-env
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          uv-version: ${{ env.UV_VERSION }}

      # Clean uv cache after install to save space
      - name: Clean uv cache
        run: |
          uv cache clean
          echo "After cache clean:"
          df -h

      # Run integration tests (requires Redis)
      - name: Run integration tests with coverage
        timeout-minutes: 25
        run: |
          echo "=== Batch 2: Integration Tests (~208 tests) ==="
          uv run pytest tests/integration/ \
            -v \
            -m "not infrastructure and not gpu" \
            --cov=src \
            --cov-report=xml:coverage-integration.xml \
            --cov-report=term \
            --cov-report=html:htmlcov-integration \
            --tb=short \
            --junitxml=test-results-integration.xml \
            -o junit_family=legacy
        env:
          # Redis is available via service container on localhost:6379
          REDIS_URL: "redis://localhost:6379"

      # Clean up test artifacts to free space
      - name: Clean test cache
        if: always()
        run: |
          rm -rf .pytest_cache
          rm -rf htmlcov-integration
          echo "After test cleanup:"
          df -h

      - name: Upload integration coverage to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage-integration.xml
          flags: pytest-integration
          name: codecov-pr-ci-integration
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload integration test results to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/test-results-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./test-results-integration.xml
          flags: pytest-integration
          name: codecov-test-results-integration
          fail_ci_if_error: false
          verbose: true

      - name: Upload integration test results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-pr-ci-integration
          path: |
            coverage-integration.xml
            test-results-integration.xml
          retention-days: 30

  # Batch 3: GPU tests (DISABLED - CIRun provisioning issues)
  # GPU tests can be run locally with: pytest -m gpu
  # See .cirun.yml for GPU runner configuration
  # TODO: Re-enable when CIRun is configured or self-hosted runner available
  #
  # gpu-tests:
  #   name: Test (GPU - Batch 3/3)
  #   runs-on: "cirun-gpu-8g--${{ github.run_id }}"
  #   permissions:
  #     pull-requests: write
  #     contents: write
  #   services:
  #     redis:
  #       image: redis:7-alpine
  #       ports:
  #         - 6379:6379
  #   steps:
  #     - uses: actions/checkout@v4
  #     - name: Run GPU tests
  #       run: pytest -m gpu
  # (Full job definition commented out - see git history for details)

  build:
    name: Build Check
    runs-on: ubuntu-latest
    needs: [lint, typecheck, test-unit, test-integration]
    # Note: gpu-tests removed from dependencies to avoid blocking on CIRun provisioning
    # GPU tests run in parallel but don't block the build
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Verify uv lock
        run: |
          uv lock --check
          uv sync --frozen

      - name: Build success
        run: |
          echo "## âœ… PR CI Build Successful!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All required quality gates passed:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Linting (ruff)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Type checking (mypy)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Unit tests (~907 tests, batch 1/3)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Integration tests (~208 tests, batch 2/3)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Code coverage (codecov)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Build verification (uv lock)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Note: GPU tests (batch 3/3) run in parallel but don't block merge." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**This PR is ready to merge!** ðŸŽ‰" >> $GITHUB_STEP_SUMMARY

  # Security scanning with Bandit
  security:
    name: Security Scan (bandit)
    runs-on: ubuntu-latest
    continue-on-error: true  # Don't block PR if security scan fails
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install bandit
        run: uv tool install bandit[toml]

      - name: Run bandit
        run: |
          uv tool run bandit -r src/ -f json -o bandit-report.json || true
          uv tool run bandit -r src/ -f txt || true

      - name: Upload security report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-report
          path: bandit-report.json
          retention-days: 30

  # Dependency vulnerability scanning
  dependency-check:
    name: Dependency Check
    runs-on: ubuntu-latest
    continue-on-error: true  # Don't block PR if dependency check fails
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Install pip-audit in project environment
        run: uv pip install pip-audit

      - name: Run pip-audit on project dependencies
        run: |
          uv run pip-audit --desc --output pip-audit-report.json --format json || true
          uv run pip-audit --desc || true

      - name: Upload dependency report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dependency-report
          path: pip-audit-report.json
          retention-days: 30
