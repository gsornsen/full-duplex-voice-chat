version: '3.8'

services:
  # Redis for service discovery
  redis:
    image: redis:7-alpine
    container_name: redis-tts
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s
    networks:
      - tts-network

  # Orchestrator service
  orchestrator:
    build:
      context: .
      dockerfile: Dockerfile.orchestrator
    container_name: orchestrator
    ports:
      - "8080:8080"  # WebSocket
      - "8081:8081"  # Health check HTTP
    environment:
      - REDIS_URL=redis://redis:6379
    depends_on:
      redis:
        condition: service_healthy
      tts0:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - tts-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # TTS worker (GPU 0)
  tts0:
    build:
      context: .
      dockerfile: Dockerfile.tts
    container_name: tts-worker-0
    ports:
      - "7001:7001"  # gRPC (changed from 7002 to match config)
      - "9090:9090"  # Metrics
    environment:
      - REDIS_URL=redis://redis:6379
      - CUDA_VISIBLE_DEVICES=0
      - WORKER_NAME=tts-worker-0
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      # For M2: Use simple port check
      # For M4+: Use grpc-health-probe
      test: ["CMD-SHELL", "nc -zv localhost 7001 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    networks:
      - tts-network
    volumes:
      - ./voicepacks:/app/voicepacks:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]

networks:
  tts-network:
    driver: bridge
