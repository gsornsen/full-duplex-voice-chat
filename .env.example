# Environment variables for Realtime Duplex Voice Demo

# =============================================================================
# TTS Configuration
# =============================================================================

# TTS Adapter Type (piper, cosyvoice2, xtts, sesame)
ADAPTER_TYPE=piper

# Default TTS Model
# For Piper: piper-en-us-lessac-medium, piper-en-us-amy-medium, etc.
# For CosyVoice: cosyvoice2-en-base, cosyvoice2-zh-base, etc.
DEFAULT_MODEL=piper-en-us-lessac-medium
DEFAULT_MODEL_ID=piper-en-us-lessac-medium

# For CosyVoice deployment, use:
# ADAPTER_TYPE=cosyvoice2
# DEFAULT_MODEL=cosyvoice2-en-base
# DEFAULT_MODEL_ID=cosyvoice2-en-base

# =============================================================================
# ASR Configuration (WhisperX)
# =============================================================================

# ASR Device Selection
# Options: auto (detect CUDA/CPU), cpu, cuda
ASR_DEVICE=auto

# WhisperX Model Size
# Options: tiny, base, small, medium, large, large-v2, large-v3
ASR_MODEL_SIZE=small

# ASR Language (ISO 639-1 code)
# Options: en, es, fr, de, zh, ja, etc.
ASR_LANGUAGE=en

# ASR Compute Type (quantization)
# Options: default, int8, float16, float32
# Note: float16 requires CUDA, int8 is faster on CPU
ASR_COMPUTE_TYPE=default

# =============================================================================
# Redis Configuration
# =============================================================================

# For Docker: use internal DNS (redis://redis:6379)
# For local dev: use localhost (redis://localhost:6379)
REDIS_URL=redis://localhost:6379

# =============================================================================
# LiveKit Configuration
# =============================================================================

# LiveKit Server URL
# For Docker: ws://livekit:7880
# For local dev: ws://localhost:7880
LIVEKIT_URL=ws://localhost:7880

# LiveKit API Credentials (match configs/livekit.yaml for local development)
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=devsecret1234567890abcdefghijklmn

# =============================================================================
# OpenAI API Configuration
# =============================================================================

# OpenAI API Key (for LLM in Phase 1)
# Required for agent mode with OpenAI LLM integration
# Will be made optional in Phase 4 for direct passthrough
OPENAI_API_KEY=sk-your-openai-api-key

# OpenAI Model Selection
# Options: gpt-4.1-mini, gpt-4o-mini, gpt-4, gpt-4-turbo, etc.
# Default: gpt-4.1-mini (standard), gpt-4o-mini (dual-LLM)
OPENAI_MODEL=gpt-4.1-mini

# =============================================================================
# Dual-LLM Configuration (Experimental)
# =============================================================================

# Enable dual-LLM strategy for reduced perceived latency
# When enabled, the agent uses template-based filler responses ("Let me think...")
# while generating the full LLM response in parallel
# Options: true, false
# Default: false
DUAL_LLM_ENABLED=false

# =============================================================================
# Parallel Synthesis Configuration (Phase C - Performance)
# =============================================================================

# Enable parallel TTS synthesis pipeline
# When enabled, multiple sentences are synthesized concurrently (2-3x throughput)
# with strict FIFO playback order maintained
# Options: true, false
# Default: false
PARALLEL_SYNTHESIS_ENABLED=false

# Number of parallel TTS workers (2-3 recommended)
# Higher values increase GPU memory usage but improve throughput
# Default: 2
PARALLEL_SYNTHESIS_NUM_WORKERS=2

# Maximum sentence queue depth (backpressure threshold)
# Controls how many sentences to buffer before slowing down LLM stream
# Default: 10
PARALLEL_SYNTHESIS_MAX_QUEUE_DEPTH=10

# Maximum concurrent GPU operations (None = unlimited)
# Set to limit GPU memory usage and prevent OOM errors
# Example: 2 (for 8GB GPU), 3 (for 12GB GPU), 4+ (for 16GB+ GPU)
# Default: 2
PARALLEL_SYNTHESIS_GPU_LIMIT=2

# =============================================================================
# Orchestrator Configuration
# =============================================================================

# Orchestrator Mode (agent or legacy)
# - agent: LiveKit Agent mode for web frontend
# - legacy: WebSocket server mode for CLI client
ORCHESTRATOR_MODE=agent

# Orchestrator Host (for legacy mode)
ORCHESTRATOR_HOST=0.0.0.0

# Orchestrator Ports (for legacy mode)
ORCHESTRATOR_WEBRTC_PORT=8080
ORCHESTRATOR_WS_PORT=8081

# TTS Worker Address (for agent mode)
# For Docker: tts:7001 (uses network alias)
# For local dev: localhost:7001
TTS_WORKER_ADDRESS=tts:7001

# =============================================================================
# Worker Configuration
# =============================================================================

# Worker Name (unique identifier for service discovery)
WORKER_NAME=tts-worker-0

# Worker Ports
WORKER_GRPC_HOST=0.0.0.0
WORKER_GRPC_PORT=7002
WORKER_METRICS_PORT=9090

# Model Configuration
PRELOAD_MODEL_IDS=

# =============================================================================
# GPU Configuration
# =============================================================================

# CUDA Device Selection (0, 1, 2, etc.)
# For multi-GPU setups, specify which GPU to use
CUDA_VISIBLE_DEVICES=0

# =============================================================================
# Logging Configuration
# =============================================================================

# Log Level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log Format (json, text)
LOG_FORMAT=json

# =============================================================================
# Development Configuration
# =============================================================================

# Debug Mode (true/false)
DEBUG=false

# Continuation Detection (Phase 1 - Smart Waiting)
# Detects and merges speech continuations after thinking pauses
# Example: "Tell me about... [pause] ...the weather" â†’ merged into one utterance
ENABLE_CONTINUATION_DETECTION=false  # Set to true to enable
